{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ad40428-e616-443d-b0a7-aba3f65e93eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b9691fb-b7ec-40de-9065-d3938bb2da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "SCRIPT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"../scripts\"))\n",
    "if SCRIPT_DIR not in sys.path:\n",
    "    sys.path.append(SCRIPT_DIR)\n",
    "from config import YEARS, RAW_PATH, PROCESSED_PATH, WDI_INDICATORS, VDEM_VARIABLES, VDEM_DOWNLOAD_URL, TARGET_VARIABLE, BARRO_LEE_FILENAME, VARIANCE_ANALYSIS, CLUSTERING_VARIABLES\n",
    "from load_vdem import load_vdem_subset\n",
    "from load_wdi import load_and_average_wdi_indicator\n",
    "from load_barro_lee import load_barro_lee_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b477a3f-8f56-49b6-81c7-330f5ad3abc6",
   "metadata": {},
   "source": [
    "# 1 Datensatz erstellen\n",
    "\n",
    "Im ersten Schritt werden die Daten aus den verschiedenen Quellen geladen und auf die für die Analyse relevanten Variablen und Jahre gefiltert. Dabei werden V-Dem-, Weltbank- und Barro-Lee-Daten jeweils separat verarbeitet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0583929-52bb-4386-a054-78ca47339a52",
   "metadata": {},
   "source": [
    "## 1.1 V-Dem: Daten laden & filtern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1f7e984-ca18-42f2-af07-6fff46157393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade V-Dem ZIP-Datei herunter ...\n",
      "Entpacke ZIP-Datei ...\n",
      "Lade und filtere CSV-Datei ...\n",
      "Berechne Durchschnitt pro Land ...\n",
      "V-Dem-Durchschnitt gespeichert unter: ../data/processed/vdem_subset_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "vdem_df, vdem_variances_df = load_vdem_subset(\n",
    "    years=YEARS,\n",
    "    variables= VDEM_VARIABLES,\n",
    "    download_url= VDEM_DOWNLOAD_URL,\n",
    "    raw_path= RAW_PATH,\n",
    "    processed_path= PROCESSED_PATH,\n",
    "    save_as=\"vdem_subset_filtered.csv\",\n",
    "    compute_variance = VARIANCE_ANALYSIS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674b6b32-ac44-43bb-9e4e-ac3a96ba6f79",
   "metadata": {},
   "source": [
    "## 1.2 WDI: Indikatoren laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9cdf697-1f41-471a-afdc-886d7d5da003",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m metadata_frames \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m wdi_variances_dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m wdi_code, name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mWDI_INDICATORS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Indikator laden + zugehörige Metadaten holen\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     df, metadata, variance \u001b[38;5;241m=\u001b[39m load_and_average_wdi_indicator(\n\u001b[0;32m      7\u001b[0m         wdi_code,\n\u001b[0;32m      8\u001b[0m         years\u001b[38;5;241m=\u001b[39mYEARS,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m         compute_variance \u001b[38;5;241m=\u001b[39m VARIANCE_ANALYSIS\n\u001b[0;32m     12\u001b[0m     )\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Spalten umbenennen\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "wdi_dfs = []\n",
    "metadata_frames = []\n",
    "wdi_variances_dfs = []\n",
    "for wdi_code in WDI_INDICATORS:\n",
    "    # Indikator laden + zugehörige Metadaten holen\n",
    "    df, metadata, variance = load_and_average_wdi_indicator(\n",
    "        wdi_code,\n",
    "        years=YEARS,\n",
    "        raw_path=RAW_PATH,\n",
    "        processed_path=PROCESSED_PATH,\n",
    "        compute_variance = VARIANCE_ANALYSIS\n",
    "    )\n",
    "\n",
    "    # Spalten umbenennen\n",
    "    wdi_dfs.append(df)\n",
    "\n",
    "    metadata_frames.append(metadata)\n",
    "    wdi_variances_dfs.append(variance)\n",
    "\n",
    "# Alle Metadaten zusammenführen\n",
    "metadata_df = pd.concat(metadata_frames, ignore_index=True)\n",
    "metadata_unique = metadata_df.drop_duplicates(subset=[\"Country Code\"])\n",
    "\n",
    "# Speichern\n",
    "meta_path = os.path.join(PROCESSED_PATH, \"Master_Metadata.csv\")\n",
    "metadata_unique.to_csv(meta_path, index=False)\n",
    "print(f\"Master-Metadaten gespeichert unter: {meta_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d14b79-3bc9-427e-ae69-cd65309a8e95",
   "metadata": {},
   "source": [
    "## 1.3. Barro-Lee: Durchschnittliche Schuljahre laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c854af87-b95a-4a5c-a73e-667114cd2f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "barro_df = load_barro_lee_subset(target_year = 2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8335f51-61a2-4a68-9dd1-18886fb45233",
   "metadata": {},
   "source": [
    "## 1.4. Varianzen berechnen\n",
    "Hintergrund: Beobachtungszeitraum & Varianzbewertung\n",
    "Ziel dieses Blocks ist es, einen geeigneten Beobachtungszeitraum (z. B. 5 oder 10 Jahre) festzulegen, der zwischen Datenverfügbarkeit und Aussagekraft eines Mittelwerts abwägt. Ein längerer Zeitraum liefert tendenziell vollständigere Daten, erhöht aber auch die Varianz innerhalb der Werte, wodurch der Mittelwert weniger repräsentativ werden kann.\n",
    "\n",
    "Deshalb wird hier die durchschnittliche Varianz je Variable berechnet.\n",
    "Die Konfiguration (YEARS) wurde dabei manuell angepasst, und das Notebook zweimal ausgeführt– einmal für 5 Jahre und einmal für 10 Jahre.\n",
    "Die berechneten Varianzen dienten ausschließlich zur Einschätzung und Auswahl des Zeitraums, nicht für die weitere Analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d90a6a-e168-409e-9c01-08765b16ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "if VARIANCE_ANALYSIS:\n",
    "    # Alle Varianz-DataFrames (WDI + V-Dem) zu einer Übersicht zusammenführen\n",
    "    df_var_summary = pd.concat(wdi_variances_dfs + [vdem_variances_df], ignore_index=True)\n",
    "\n",
    "    # Nach mittlerer Varianz über Länder sortieren\n",
    "    df_var_summary = df_var_summary.sort_values(\"Median Varianz über Länder\", ascending=True)\n",
    "\n",
    "    # Ergebnis als CSV-Datei speichern\n",
    "    filename = f\"df_var_summary_{min(YEARS)}_{max(YEARS)}.csv\"\n",
    "    output_path = os.path.join(PROCESSED_PATH, filename)\n",
    "    df_var_summary.to_csv(output_path, index=False)\n",
    "    print(f\"Varianz-Zusammenfassung gespeichert unter: {output_path}\")\n",
    "\n",
    "    # Berechnung und Ausgabe der Gesamt-Medianvarianz zur Einordnung\n",
    "    gesamt_median = df_var_summary[\"Median Varianz über Länder\"].median()\n",
    "    print(f\"Gesamter Mittelwert der Länder-Varianzen über alle Variablen: {gesamt_median:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18c2557-9597-404f-ae3b-33d4834babc5",
   "metadata": {},
   "source": [
    "## 1.5 Datensätze mergen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b34ad4-60cb-4c9c-8bf1-1e0666c806e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country-Namen aus V-DEM-Frame extrahieren\n",
    "country_names = vdem_df[[\"Country Code\", \"Country Name\"]].drop_duplicates()\n",
    "\n",
    "# WDI-Frames ohne \"Country Name\" vorbereiten, um Mergen zu erleichtern\n",
    "wdi_clean = [df.drop(columns=[\"Country Name\"], errors=\"ignore\") for df in wdi_dfs]\n",
    "\n",
    "# Weltbankdaten zu Hauptdatensatz mergen\n",
    "df_master = reduce(lambda left, right: pd.merge(left, right, on=\"Country Code\", how=\"outer\"), wdi_clean)\n",
    "\n",
    "# Barro-Lee vorbereiten \n",
    "barro_df_clean = barro_df.drop(columns=[\"Country Name\"], errors=\"ignore\")\n",
    "\n",
    "# Barro-Lee in Hauptdatensatz mergen\n",
    "df_master = pd.merge(df_master, barro_df_clean, on=\"Country Code\", how=\"outer\")\n",
    "\n",
    "# Metadata vorbereiten \n",
    "metadata_df_clean = metadata_df.drop(columns=[\"TableName\",\"SpecialNotes\"], errors=\"ignore\")\n",
    "\n",
    "# Metadata in Hauptdatensatz mergen\n",
    "df_master = pd.merge(df_master, metadata_df_clean, on=\"Country Code\", how=\"outer\")\n",
    "\n",
    "# V-Dem vorbereiten \n",
    "vdem_df_clean = vdem_df.drop(columns=[\"Country Name\"], errors=\"ignore\")\n",
    "\n",
    "# V-Dem in Hauptdatensatz mergen(hier werden nur Länder mit existierendem Wert für die Zielvariable verwendet)\n",
    "vdem_valid = vdem_df_clean[vdem_df_clean[\"v2x_partipdem\"].notna()]\n",
    "df_master = pd.merge(df_master, vdem_valid, on=\"Country Code\", how=\"inner\")\n",
    "\n",
    "# Country Name wieder anhängen\n",
    "df_master = pd.merge(country_names, df_master, on=\"Country Code\", how=\"right\")\n",
    "\n",
    "# Entferne leere \"Unnamed\"-Spalten\n",
    "df_master = df_master.loc[:, ~df_master.columns.str.contains(\"^Unnamed\")]\n",
    "df_master = df_master.drop_duplicates(subset=[\"Country Code\"])\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "print(f\"Finale Länderanzahl: {df_master.shape[0]}\")\n",
    "print(f\"Spaltenanzahl: {df_master.shape[1]}\")\n",
    "\n",
    "# Speichern\n",
    "output_path = os.path.join(PROCESSED_PATH, \"merged_dataset.csv\")\n",
    "df_master.to_csv(output_path, index=False)\n",
    "print(f\"Master-Datensatz gespeichert unter: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7ac20b-0fc7-4af1-9a34-ec2b3ca83de4",
   "metadata": {},
   "source": [
    "# 2 Preprocessing der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1dd3c8-6bdc-4680-aecb-c09ba8c11713",
   "metadata": {},
   "source": [
    "## 2.1 Analyse fehlender Werte und Datenabdeckung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c869354-9824-465b-8def-876bbf0ede81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anteil fehlender Werte je Variable\n",
    "missing_per_variable = df_master.isna().mean().sort_values(ascending=False)\n",
    "print(missing_per_variable)\n",
    "\n",
    "# Anteil fehlener Werte je Land\n",
    "df_tmp = df_master.set_index(\"Country Code\")\n",
    "missing_per_country = 1 - (df_tmp.notna().sum(axis=1) / df_tmp.shape[1])\n",
    "missing_per_country = missing_per_country.sort_values(ascending=False)\n",
    "print(missing_per_country.head(60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c4601c-01c6-4fc3-a581-9eb1dfea5743",
   "metadata": {},
   "source": [
    "## 2.2 Random Forest Imputation fehlender Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355bfbc9-77eb-4897-8eb3-98912e163b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taiwan wurde aufgrund vollständig fehlender sozioökonomischer Kontextdaten (Weltbankindikatoren) aus der Analyse ausgeschlossen.\n",
    "df_master = pd.read_csv(\"../data/processed/merged_dataset.csv\")\n",
    "df_master = df_master[df_master[\"Country Code\"] != \"TWN\"] \n",
    "\n",
    "# Income Groupe von Venezuela Manuell zu Upper-middle-income setzen, da fehlend in Datensatz\n",
    "df_master.loc[df_master[\"Country Code\"] == \"VEN\", \"IncomeGroup\"] = \"Upper-middle-income\"\n",
    "\n",
    "# Spalten mit fehlenden numerischen Werten finden\n",
    "numerical_cols = df_master.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "cols_with_na = [col for col in numerical_cols if df_master[col].isna().sum() > 0]\n",
    "\n",
    "# Imputer initialisieren \n",
    "imputer = IterativeImputer(\n",
    "    estimator=RandomForestRegressor(n_estimators=100, random_state=0),\n",
    "    max_iter=10,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# Nur numerische Spalten mit NaNs imputieren\n",
    "df_imputed_values = imputer.fit_transform(df_master[cols_with_na])\n",
    "\n",
    "# In DataFrame umwandeln\n",
    "df_imputed = pd.DataFrame(df_imputed_values, columns=cols_with_na, index=df_master.index)\n",
    "\n",
    "# Original DataFrame aktualisieren\n",
    "df_master.loc[:, cols_with_na] = df_imputed\n",
    "\n",
    "# 5. Zwischenergebnis speichern\n",
    "output_path = \"../data/processed/merged_dataset_imputed.csv\"\n",
    "df_master.to_csv(output_path, index=False)\n",
    "print(f\"Imputation abgeschlossen und gespeichert unter: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761b999b-daab-417f-9573-675945814ab6",
   "metadata": {},
   "source": [
    "## 2.3 Erneute Analyse fehlender Werte und Datenabdeckung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555be6a-f232-43bf-ad07-d5eade8bdd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anteil fehlender Werte je Variable\n",
    "missing_per_variable = df_master.isna().mean().sort_values(ascending=False)\n",
    "print(missing_per_variable.head(10))\n",
    "\n",
    "# Anteil fehlener Werte je Land\n",
    "df_tmp = df_master.set_index(\"Country Code\")\n",
    "missing_per_country = 1 - (df_tmp.notna().sum(axis=1) / df_tmp.shape[1])\n",
    "missing_per_country = missing_per_country.sort_values(ascending=False)\n",
    "print(missing_per_country.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca93f785-6d27-4c53-8575-00040caba2c6",
   "metadata": {},
   "source": [
    "# 3 Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74ec7db-dc39-4759-8564-7d09a1e8da93",
   "metadata": {},
   "source": [
    "## 3.1 Korrelationsanalyse \n",
    "\n",
    "Bevor ein Modell zur Bestimmung der Einflussfaktoren auf die partizipative Demokratie (Zielvariable: v2x_partipdem) erstellt wird, ist es wichtig zu prüfen, ob einige der potenziellen Prädiktoren stark miteinander korrelieren. Hohe Korrelationen zwischen erklärenden Variablen (Multikollinearität) können Modellverzerrungen verursachen und die Interpretation erschweren.\n",
    "\n",
    "In diesem Schritt werden daher:\n",
    "- alle numerischen Variablen außer der Zielvariable extrahiert,\n",
    "- eine Korrelationsmatrix auf Basis der absoluten Pearson-Korrelation berechnet,\n",
    "- stark korrelierte Paare (Schwellenwert: > 0.85) identifiziert und tabellarisch ausgegeben,\n",
    "- eine visuelle Heatmap zur Übersicht aller Korrelationen dargestellt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5c3f2c-14f8-497b-bfaf-cfcf66acf232",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = df_master.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "feature_cols = [col for col in feature_cols if col != TARGET_VARIABLE]\n",
    "df_feat = df_master[feature_cols]\n",
    "\n",
    "# Korrelationsmatrix erstellen\n",
    "corr_matrix = df_feat.corr().abs()\n",
    "\n",
    "# Korrelationsanalyse\n",
    "high_corr_df = (\n",
    "    corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    .stack()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: \"Korrelationskoeffizient\"})\n",
    "    .query(\"Korrelationskoeffizient > 0.85\")\n",
    "    .sort_values(by=\"Korrelationskoeffizient\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"Stark korrelierte Variablenpaare:\")\n",
    "print(high_corr_df.to_string(index=False))\n",
    "\n",
    "# Heatmap anzeigen \n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(corr_matrix, cmap=\"coolwarm\", annot=False, center=0)\n",
    "plt.title(\"Korrelationsmatrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13449403-513b-4419-af50-3152f89a3b06",
   "metadata": {},
   "source": [
    "## 3.2 Globale Feature Importance Analyse \n",
    "\n",
    "In diesem Schritt wird ein Random-Forest-Modell verwendet, um die relative Bedeutung (Feature Importance) aller potenziellen Einflussfaktoren auf den Partizipationsindex (v2x_partipdem) zu bestimmen. Die Analyse erfolgt global, also über alle Länder hinweg. Die resultierenden Wichtigkeitswerte geben an, welche Merkmale den größten Beitrag zur Erklärung der Zielvariable leisten.\n",
    "Basierend auf diesen Werten können irrelevante oder wenig aussagekräftige Variablen identifiziert und aus der weiteren Analyse ausgeschlossen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd347e49-0582-49bd-ab8f-dce63b86506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eingabe-Features (X) und Zielvariable (y) definieren\n",
    "X = df_master[feature_cols].copy()\n",
    "y = df_master[TARGET_VARIABLE].copy()\n",
    "\n",
    "# Random Forest Modell initialisieren und trainieren\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Feature Importance berechnen und in DataFrame umwandeln\n",
    "importances = pd.DataFrame({\n",
    "    \"Feature\": feature_cols,\n",
    "    \"Importance\": model.feature_importances_\n",
    "}).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "print(\"\\n Feature Importance (Random Forest für v2x_partipdem):\")\n",
    "print(importances.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e21d6f-bb21-4cd9-bbbe-f02afbc46d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diese vier Variablen werden wegen starker Korrelation mit andern Variablen und auf Basis der Feature Importance entfernt\n",
    "vars_to_drop = [\"v2x_rule\", \"v2x_corr\", \"v2dlconslt\", \"v2xlg_legcon\"]\n",
    "\n",
    "df_cleaned = df_master.drop(columns=vars_to_drop)\n",
    "df_cleaned.to_csv(\"../data/processed/merged_dataset_cleaned.csv\", index=False)\n",
    "print(\"Datensatz ohne stark korrelierte Variablen gespeichert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f003ca51-10b3-49f8-b9e6-a4bbe6709210",
   "metadata": {},
   "source": [
    "## 3.3. Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e071a312-cc7c-4cde-b385-d180fe2c305e",
   "metadata": {},
   "source": [
    "### 3.3.1 Skalieren\n",
    "\n",
    "Um sicherzustellen, dass alle Einflussfaktoren im Clustering möglichst gleich gewichtet werden, werden die ausgewählten numerischen Variablen mittels Standardisierung (StandardScaler) auf Mittelwert = 0 und Standardabweichung = 1 gebracht. Dies verhindert, dass Variablen mit größeren Wertebereichen (z. B. BIP) den Clustering-Prozess dominieren. Die beiden Variablen Inflation und Bevölkerungszahl wurden vom Clustering ausgeschlossen, da sie sich als potenzielle Verzerrungsfaktoren erwiesen – etwa durch extreme Ausreißer (Inflation) oder enorm unterschiedliche Skalenniveaus (Bevölkerung), die selbst nach Standardisierung zu einer unangemessenen Gewichtung im Clustering führen könnten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d25a14-39eb-4aa9-beed-0dae001ad6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skalieren\n",
    "scaler = StandardScaler()\n",
    "scaled_values = scaler.fit_transform(df_cleaned[CLUSTERING_VARIABLES])\n",
    "df_scaled = pd.DataFrame(scaled_values, columns=[f\"{col}\" for col in CLUSTERING_VARIABLES])\n",
    "\n",
    "# Kontextspalten beibehalten \n",
    "context_cols = [\"Country Code\", \"Country Name\", \"Region\", \"IncomeGroup\"]\n",
    "for col in context_cols:\n",
    "    if col in df_cleaned.columns:\n",
    "        df_scaled[col] = df_cleaned[col]\n",
    "output_path = \"../data/processed/cluster_input_scaled.csv\"\n",
    "df_scaled.to_csv(output_path, index=False)\n",
    "print(f\" Skalierte Variablen gespeichert unter: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476309fb-71da-434d-a65d-5113f4d2452c",
   "metadata": {},
   "source": [
    "### 3.3.2 Anzahl der Cluster bestimmen\n",
    "\n",
    "Um eine geeignete Anzahl an Clustern für die anschließende Gruppierung der Länder zu finden, werden zwei gängige Metriken angewendet: die Elbow-Methode (Inertia) und der Silhouette Score. Beide helfen dabei abzuschätzen, bei welcher Clusteranzahl eine sinnvolle Balance zwischen Homogenität innerhalb der Cluster und Trennschärfe zwischen den Clustern erreicht wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84344e17-5390-4bd0-8182-015c79fb9701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Auswahl (alle numerischen Spalten ohne Kontextspalten)\n",
    "context_cols = [\"Country Code\", \"Country Name\", \"Region\", \"IncomeGroup\"]\n",
    "feature_cols = [col for col in df_scaled.columns if col not in context_cols]\n",
    "\n",
    "X = df_scaled[feature_cols]\n",
    "\n",
    "# Cluster-Anzahl-Bereich\n",
    "k_range = range(2, 11)\n",
    "\n",
    "# Ergebnisse speichern\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=\"auto\")\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X, labels))\n",
    "\n",
    "# Visualisierung\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Elbow Plot\n",
    "ax[0].plot(k_range, inertias, marker=\"o\")\n",
    "ax[0].set_xlabel(\"Anzahl der Cluster (k)\")\n",
    "ax[0].set_ylabel(\"Inertia (Summe der quadrierten Distanzen)\")\n",
    "ax[0].set_title(\"Elbow-Methode\")\n",
    "\n",
    "# Silhouette Plot\n",
    "ax[1].plot(k_range, silhouette_scores, marker=\"o\", color=\"orange\")\n",
    "ax[1].set_xlabel(\"Anzahl der Cluster (k)\")\n",
    "ax[1].set_ylabel(\"Silhouette Score\")\n",
    "ax[1].set_title(\"Silhouette Scores\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd79255-23d3-44d2-8f4a-f41b37889531",
   "metadata": {},
   "source": [
    "### 3.3.3 Clustering durchführen\n",
    "\n",
    "Basierend auf den Ergebnissen der Elbow-Methode und der Silhouette-Analyse wurde entschieden, drei Cluster zu bilden. Diese Konfiguration bietet einen guten Kompromiss zwischen interner Homogenität und externer Trennschärfe der Cluster. \n",
    "\n",
    "Die Zuordnung zu den Clustern erfolgt nun mittels des KMeans-Algorithmus basierend auf den skalierten sozioökonomischen Variablen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e746d6-cdd5-493f-a002-1b87612b08e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans-Modell initialisieren und fitten\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=\"auto\")\n",
    "df_scaled[\"cluster\"] = kmeans.fit_predict(df_scaled[CLUSTERING_VARIABLES])\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "print(\"Cluster-Zuweisung abgeschlossen.\")\n",
    "\n",
    "# Abspeichern\n",
    "output_path = \"../data/processed/merged_dataset_clustered.csv\"\n",
    "df_scaled.to_csv(output_path, index=False)\n",
    "print(f\"Ergebnis gespeichert unter: {output_path}\")\n",
    "\n",
    "\n",
    "print(\"Anzahl der Länder pro Cluster:\")\n",
    "print(df_scaled[\"cluster\"].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5e3720-8823-4be5-a74f-c30bbeb2f7a9",
   "metadata": {},
   "source": [
    "Bevor die einzelnen Cluster im Detail analysiert und interpretiert werden, erfolgt zunächst eine Visualisierung der Clusterstruktur. Hierzu wurde eine Hauptkomponentenanalyse (PCA) durchgeführt, um die hochdimensionalen Daten auf zwei Dimensionen zu reduzieren. Die folgende Darstellung zeigt die räumliche Verteilung der Länder im PCA-Raum, farblich differenziert nach ihrer jeweiligen Clusterzugehörigkeit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15052dfd-dd43-4b4a-8e7c-21f4f3dea719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hauptkomponentenanalyse (PCA) mit zwei Komponenten zur Visualisierung\n",
    "pca = PCA(n_components=2)\n",
    "components = pca.fit_transform(df_scaled[feature_cols])\n",
    "df_scaled[\"PCA1\"], df_scaled[\"PCA2\"] = components[:,0], components[:,1]\n",
    "\n",
    "# Scatter-Plot zur Darstellung der Cluster im zweidimensionalen PCA-Raum\n",
    "plt.figure(figsize=(10, 6))\n",
    "for cluster in sorted(df_scaled[\"cluster\"].unique()):\n",
    "    subset = df_scaled[df_scaled[\"cluster\"] == cluster]\n",
    "    plt.scatter(subset[\"PCA1\"], subset[\"PCA2\"], label=f\"Cluster {cluster}\")\n",
    "plt.legend()\n",
    "plt.title(\"Cluster-Verteilung in PCA-Raum\")\n",
    "plt.xlabel(\"PCA1\")\n",
    "plt.ylabel(\"PCA2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af66aab-7884-46e3-a729-aaddce371b7f",
   "metadata": {},
   "source": [
    "Die PCA-Grafik zeigt eine insgesamt gute Trennung der Cluster, insbesondere Cluster 1 ist klar abgegrenzt. In Kombination mit den Ergebnissen der Elbow-Methode und der Silhouette-Analyse bestätigt dies die Wahl von drei Clustern als geeignete Grundlage für die weitere Analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3b07c8-a08e-4e1d-8daa-98d15bf1c7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gesamter Silhouettenkoeffizient\n",
    "sil_score = silhouette_score(df_scaled[CLUSTERING_VARIABLES], df_scaled[\"cluster\"])\n",
    "print(f\"Silhouettenkoeffizient für k=3: {sil_score:.3f}\")\n",
    "\n",
    "# Optional: Silhouettenwerte für jedes Land\n",
    "df_scaled[\"silhouette_score\"] = silhouette_samples(df_scaled[CLUSTERING_VARIABLES], df_scaled[\"cluster\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68af000a-8261-40f4-a915-f54800e7c9c9",
   "metadata": {},
   "source": [
    "Zur Bewertung der internen Trennschärfe der Cluster wurde der durchschnittliche Silhouettenkoeffizient berechnet. Für die gewählte Clusteranzahl von k=3 ergibt sich ein Wert von 0.355. Dieser liegt im mittleren Bereich und deutet auf eine mäßig klare Abgrenzung der Cluster hin. \n",
    "\n",
    "Während der Wert keine sehr starke Strukturierung der Daten signalisiert, ist er für sozialwissenschaftliche Kontexte mit komplexen und überlappenden Merkmalen durchaus als akzeptabel zu bewerten – insbesondere bei explorativen Analysen mit heterogenen Ländern als Beobachtungseinheiten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b0a8e-6d3e-4076-8618-627f2369df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cluster Zentren:\")\n",
    "print(pd.DataFrame(kmeans.cluster_centers_, columns=CLUSTERING_VARIABLES))\n",
    "\n",
    "# Verteilung der Einkommensgruppen in den Clustern\n",
    "print(\"Verteilung der Einkommensgruppen pro Cluster:\")\n",
    "print(pd.crosstab(df_scaled[\"cluster\"], df_scaled[\"IncomeGroup\"]), \"\\n\")\n",
    "\n",
    "# Verteilung der Weltregionen in den Clustern\n",
    "print(\"Verteilung der Weltregionen pro Cluster:\")\n",
    "print(pd.crosstab(df_scaled[\"cluster\"], df_scaled[\"Region\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4b6085-9e1e-4c16-96b8-55f8731fc284",
   "metadata": {},
   "source": [
    "Interpretation der Cluster\n",
    "\n",
    "\n",
    "Cluster 0 vereint Länder mit mittleren sozioökonomischen Merkmalen. Sie zeigen moderate Werte bei BIP pro Kopf, Urbanisierung, Internetnutzung und Bildung. Die Gruppe enthält sowohl „High income“ als auch „Lower middle income“ und „Upper middle income“ Länder und ist regional stark in Europa, Lateinamerika und MENA vertreten. Die Heterogenität deutet auf einen strukturell gemischten Übergangscluster hin.\n",
    "\n",
    "Cluster 1 zeigt sehr hohe Werte bei nahezu allen sozioökonomischen Indikatoren – insbesondere bei BIP pro Kopf, Internetnutzung, Urbanisierung und Bildungsniveau. Es handelt sich ausschließlich um Hochlohnländer, vorwiegend aus Europa, Nordamerika und Ostasien. Der Cluster repräsentiert damit klar die strukturell am weitesten entwickelten Staaten.\n",
    "\n",
    "Cluster 2 bildet die sozioökonomisch schwächste Ländergruppe ab. Diese Länder weisen niedrige Werte bei Einkommen, Bildung und Infrastruktur auf. Der Cluster setzt sich fast ausschließlich aus „Low income“ und „Lower middle income“ Ländern zusammen, mit starker Präsenz in Subsahara-Afrika und Südasien. Er steht für Länder mit starkem strukturellem Entwicklungsbedarf."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43823521-5219-410b-a395-f4a11a747a4c",
   "metadata": {},
   "source": [
    "## 3.4 Feature-Importance-Analyse innerhalb der Cluster\n",
    "\n",
    "Zunächst wird ein Random-Forest-Modell auf dem Gesamtdatensatz trainiert, um die wichtigsten Einflussfaktoren auf die partizipative Demokratie zu identifizieren. Anschließend erfolgt dieselbe Analyse für jedes Cluster separat, um Unterschiede im Einfluss struktureller Merkmale zwischen Ländergruppen sichtbar zu machen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e857ebb-96eb-4eec-a992-b0733102c4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_cleaned.merge(df_scaled[[\"Country Code\", \"cluster\"]], on=\"Country Code\", how=\"left\")\n",
    "\n",
    "# Zielvariable & Kontext\n",
    "cluster_col = \"cluster\"\n",
    "\n",
    "# Features: alle numerischen Spalten außer der Zielvariable\n",
    "exclude_cols = [\"Country Code\", \"Country Name\", \"Region\", \"IncomeGroup\", TARGET_VARIABLE, cluster_col]\n",
    "feature_cols = [col for col in df_final.select_dtypes(include=[\"float64\", \"int64\"]).columns if col not in exclude_cols]\n",
    "\n",
    "# Globale Feature Importance (über alle Länder hinweg)\n",
    "print(\"\\n Globale Feature Importance – Gesamtdatensatz\")\n",
    "X_all = df_final[feature_cols]\n",
    "y_all = df_final[TARGET_VARIABLE]\n",
    "\n",
    "rf_global = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "rf_global.fit(X_all, y_all)\n",
    "\n",
    "global_importances = pd.DataFrame({\n",
    "    \"Feature\": feature_cols,\n",
    "    \"Importance\": rf_global.feature_importances_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(\n",
    "    data=global_importances.head(15),\n",
    "    x=\"Importance\",\n",
    "    y=\"Feature\",\n",
    "    hue=\"Feature\",\n",
    "    palette=\"viridis\",\n",
    "    legend=False\n",
    ")\n",
    "plt.title(\"Globale Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Feature Importance für jeden Cluster\n",
    "for cluster in sorted(df_final[cluster_col].dropna().unique()):\n",
    "    print(f\"\\n Cluster {cluster} – Länderanzahl: {df_final[df_final[cluster_col] == cluster].shape[0]}\")\n",
    "\n",
    "    # Daten aus Cluster extrahieren\n",
    "    df_cluster = df_final[df_final[cluster_col] == cluster]\n",
    "\n",
    "    # X und y\n",
    "    X = df_cluster[feature_cols]\n",
    "    y = df_cluster[TARGET_VARIABLE]\n",
    "\n",
    "    # Modell trainieren\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    rf.fit(X, y)\n",
    "\n",
    "    # Feature Importance extrahieren\n",
    "    importances = rf.feature_importances_\n",
    "    fi_df = pd.DataFrame({\n",
    "        \"Feature\": feature_cols,\n",
    "        \"Importance\": importances\n",
    "    }).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(\n",
    "    data=fi_df.head(15),\n",
    "    x=\"Importance\",\n",
    "    y=\"Feature\",\n",
    "    hue=\"Feature\",\n",
    "    palette=\"viridis\",\n",
    "    legend=False\n",
    ")\n",
    "    plt.title(f\"Top Feature Importances – Cluster {cluster}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c9c1f1-5ed0-4118-bf2c-7e35df299d0d",
   "metadata": {},
   "source": [
    "Die Visualisierungen der Feature-Importance-Analyse zeigen, dass sich die wichtigsten Einflussgrößen auf partizipative Demokratie je nach Cluster deutlich unterscheiden.\n",
    "\n",
    "In Cluster 0 stehen mit v2mecenefi (Effektivität der Medienfreiheit) und v2x_jucon (Unabhängigkeit der Justiz) zwei institutionelle Merkmale im Vordergrund, die besonders stark mit partizipativer Demokratie assoziiert sind.\n",
    "\n",
    "In Cluster 1 hingegen sind v2xeg_eqaccess (Gleichberechtigter Zugang zu Bildung, Justiz und Arbeit), v2clsocgrp (Einbindung gesellschaftlicher Gruppen) und v2psplats (politischer Pluralismus auf lokaler Ebene) die wichtigsten Merkmale. Dies deutet darauf hin, dass in dieser Ländergruppe soziale Inklusion und gleichberechtigte Teilhabe eine stärkere Rolle spielen.\n",
    "\n",
    "In Cluster 2 zeigt sich eine Mischung aus institutionellen (z. B. v2x_jucon, v2mecenefi) und infrastrukturellen Faktoren wie v2xeg_eqaccess und v2dlengage (öffentliche Deliberation). Dies spricht für ein intermediäres Profil, in dem sowohl staatliche Strukturen als auch gesellschaftliche Diskurse relevant sind.\n",
    "\n",
    "Die Unterschiede in den Rangfolgen und den dominanten Einflussgrößen legen nahe, dass partizipative Demokratie in verschiedenen Kontexten durch unterschiedliche Faktoren gefördert oder gehemmt wird."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
